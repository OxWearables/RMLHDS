{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 2: Features\n",
    "Before you start this practical, you should follow the the same steps in the practical 1 to annoate your own camera data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from scipy import stats as st\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the raw accelerometer data stored in your data folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths for where you have stored 'myAcc.csv' \n",
    "# and the annotations file, change where necesssary.\n",
    "\n",
    "dataDir= '../data/'\n",
    "rawPath = dataDir + 'myAcc.csv.gz'\n",
    "annoPath = dataDir + 'my-annotations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the raw acceleration file.\n",
    "# if you only have myAcc.csv.gz, you need to run 'gunzip myAcc.csv.gz' in your terminalfirst.\n",
    "#date_parser = lambda ts: pd.to_datetime([s[:-4] for s in ts])\n",
    "#raw = pd.read_csv(rawPath, parse_dates=['time'], date_parser=date_parser)\n",
    "raw = pd.read_csv(rawPath)\n",
    "raw['time'] = pd.to_datetime(raw['time'].str.split('+').str[0])\n",
    "\n",
    "# read the annotation file you made.\n",
    "annoData = pd.read_csv(annoPath, parse_dates=['startTime', 'endTime'], date_parser=date_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Exploration\n",
    "\n",
    "We first want to explore the raw data we have, a good first step is to plot the acceleration traces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot traces for your first 5 minutes of wearing the accelerometer\n",
    "timesteps = 100 * 60 * 5 # i.e. 100Hz x 60 seconds/min x 5 mins\n",
    "\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "pylab.rcParams['figure.figsize'] = (12, 3)\n",
    "\n",
    "acc = raw[['x', 'y', 'z']][:timesteps]\n",
    "acc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging annotations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the annotations you made using the browser with the raw acceleration traces by comparing their timestamps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['time'] = pd.to_datetime(raw['time'].str.split('+').str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['annotation'] = 'undefined'\n",
    "\n",
    "for i, row in annoData.iterrows():\n",
    "    start, end = row['startTime'].tz_localize(None), row['endTime'].tz_localize(None)\n",
    "    raw.loc[(raw['time'] > start) & (raw['time'] < end), 'annotation'] = row['annotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Can you pick an activity and plot an example acceleration trace for it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Preprocessing\n",
    "\n",
    "In this part, we attempt to process your acceleration traces into typical features used in machine learning. \n",
    "\n",
    "<!-- The following exercises consists of dividing your acceleration trace into fixed time windows and creating features out of them.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by running a sliding window function over your acceleration time series. We can produce data in windows of 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pre\n",
    "\n",
    "freq = 100 # 100Hz\n",
    "SLIDING_WINDOW_SIZE = 30 * freq # 30 seconds\n",
    "SLIDING_WINDOW_STEP = SLIDING_WINDOW_SIZE # no overlapping between windows.\n",
    "\n",
    "cols  = list(raw)\n",
    "sliding_datasets = {}\n",
    "slide = pre.sliding_window(raw.values, (SLIDING_WINDOW_SIZE,1),  \n",
    "                         ss=(SLIDING_WINDOW_STEP,1), flatten=False)\n",
    "\n",
    "# reshape sliding output to desired shape: (# windows, # features, # window length)\n",
    "slide = slide.reshape(-1, len(cols), SLIDING_WINDOW_SIZE)\n",
    "\n",
    "print('Data shape: ', slide.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that this should be equal to the length of our raw accelerometer trace divided into 30-second windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our raw accelerometer trace is {} seconds long, which gives gives {} 30-second windows.'.format(\n",
    "    int(len(raw)/freq), int(len(raw)/freq/30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to extract from each window the sensor time series, timestamp, and annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor readings windows\n",
    "sensor_cols = [cols.index(i) for i in ['x', 'y', 'z']]\n",
    "windows = slide[:, sensor_cols, :].astype(np.float)\n",
    "\n",
    "# timestamp: we use the start time of each window\n",
    "windows_time = slide[:, cols.index('time'), 0]\n",
    "\n",
    "# annotation: we use the annotation at the start of each window\n",
    "windows_anno = slide[:, cols.index('annotation'), 0]\n",
    "\n",
    "print('Shape of windowed sensor readings: {}'.format(windows.shape))\n",
    "print('Shape of timestamps: {}, annotations: {}'.format(windows_time.shape, windows_anno.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task:\n",
    "Define windows_anno instead by selecting the _dominant_ annotation within each window, i.e. the label that occurs the most number of times within each 30-second window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Processing into features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way to handle acceleration time series is to perform Discrete Fourier Transform (DFT) on the raw data. The transformed waveform will be used in the feature extraction stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_fft = np.fft.fft(windows)\n",
    "fftr = windows_fft.real.astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the windowed raw and QFT-transformed data prepared, we are ready to extract features from them.\n",
    "\n",
    "Some commonly used features are listed below. \n",
    "1. The mean of the raw signal\n",
    "2. The standard dev. of the raw signal\n",
    "3. The median of the transformed signal\n",
    "4. The interquartiles (Q1) of the transformed signal\n",
    "5. The interquartiles (Q3) of the transformed signal\n",
    "6. The skewness of the transformed signal\n",
    "7. The kurtosis of the transformed signal\n",
    "\n",
    "### Task\n",
    "Extract the above feature for your data. Present them as a dataframe with 22 columns (7 features * 3 axis + 1 annotation), and time as its index column, which should look like the following. Save your dataframe as a csv at your 'wearables/data/my_dataset.csv'\n",
    "\n",
    "<img src=\"./df.png\">\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
